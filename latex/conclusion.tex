\chapter{Conclusion}
This paper presents a framework for testing the performance of \acrshort{spsc} \acrshort{fifo} queues.
This framework simplifies the process of testing the performance of those queues, by only requiring small
modifications to the main function of the framework and that the queue implements a common interface.
Through its modular architecture, the framework also makes it easier to test the queues under multiple
different conditions.
Furthermore, parameters for queues and benchmarks are stored in config files, making sets of them simpler to
manage and to keep different version of.
This framework was used in this thesis to test different queues and has shown its ease of use in the process.
Collectively, this framework should lessen the work required of future authors to test proposed queue design
in a replicable and comparable manner.

In this work, I also tested the performance of six different queues in three different benchmarks with four
variations each.
In part, the results from these tests show significant similarities to those presented in the EQueue,
B-Queue, and FastForward papers, however, there are also significant differences that were
observed\cite{EQueue,B-Queue,FastForward}.
Several potential reasons for these differences were identified.
First, there is the possibility that the results from the EQueue paper were measured in their cross-cpu
configuration which would present a significant difference to the benchmarks performed here.
Second, the parameters of the other queues benchmarked in the EQueue paper are not know and might thus be
significantly different to those used here.
Third, the three papers did not specify what steps they took to isolate outside influences on their results,
and it is thus not clear how those differ from the approach taken here.
Fourth, inevitably the results of all papers were obtained on different hardware which, especially for the
B-Queue paper, might also be a reason for the differences.
In writing this paper, I have attempted to minimise the issues mentioned above, and those not repeated here,
by publishing the full source code required to replicate my measurements, providing detailed contextual
information, and outlining my reasoning for key decisions made in the process.

Given that FastForward queue and FastFlow queue were among the queue with the best performance in almost
every benchmark, it is recommended that they be the first candidates when choosing a queue imlpementation.
Similary, MCRingBuffer performed only slightly worse than these two queues and therefore also makes for a
good candidate.
However, given the differences between the results found here and in other papers, it is still recommended to
test multiple different queues in the concrete application that the chosen queue will be used in.
This should also require a reduced amount of work, due to the queue implementations tested here all
implementing the same interface and having their source code published.
Lastly, should the number of queues that can be tested be limited, the results presented here should give
application developers insight into which candidates to prioritise.

Building on the work done in this thesis, future contributions could include additional benchmarks featuring,
for example, multiple producer and consumer threads on the same core or more realistic simulated work loads.
Additionally, more sophisticated analysis of the data produced by the benchmarks could also be done.
This could include analysing the difference between completed enqueue and dequeue operations, or the number of
of failed operations, over time.
Lastly, a measurer component could be implemented to measure cache statistic, specificly the cache miss
percentage, which was not implemented in this thesis due to time constraints.
This was done in other papers, including the EQueue and B-Queue papers, and could be interesting to
investigate the performance differences between the queues.
However, these cache statistics should be measured per operation and not include the benchmarking code,
in line with the existing measurements.
This might be possible using the oprofile tool also used in the B-Queue paper, however, due to function
inlining a different approach might be needed.
